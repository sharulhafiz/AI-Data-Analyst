{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load top features from pickel file\n",
    "import pickle\n",
    "\n",
    "top_features = pickle.load(open('top_features.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PROJECT_AREAS_ENERGY_SUSTAINABILITY</th>\n",
       "      <td>28.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KEYNOTE_SPEAKER_INVITED</th>\n",
       "      <td>219.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARTNERSHIP_COUNTRY_N_A</th>\n",
       "      <td>79.954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARTNERSHIP_NATIONAL</th>\n",
       "      <td>48.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROJECT_AREAS_BIOMEDICAL_AND_HEALTHCARE_ENGINEERING</th>\n",
       "      <td>32.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROJECT_AREAS_ENERGY_SECURITY</th>\n",
       "      <td>35.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROJECT_AREAS_NATURAL_PRODUCTS_BIOREFINERY_AND_BIOTECHNOLOGY</th>\n",
       "      <td>44.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROJECT_AREAS_SMART_LIVING_AND_SUSTAINABLE_CITIES</th>\n",
       "      <td>71.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROJECT_AREAS_SMART_MANUFACTURING_AND_MATERIALS</th>\n",
       "      <td>62.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROJECT_AREAS_SUSTAINABLE_AND_RESILIENT_URBANISATION</th>\n",
       "      <td>73.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCHOLARSHIP_PHD</th>\n",
       "      <td>72.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCHOLARSHIP_MASTER</th>\n",
       "      <td>19.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONFERENCE_NATIONAL_INCLUDE_UNIVERSITY_LEVEL</th>\n",
       "      <td>44.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAPER_INCENTIVE_NO_OF_PAPER_STAFF</th>\n",
       "      <td>672.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCORE_OVERALL_RANK</th>\n",
       "      <td>189.782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Mean\n",
       "PROJECT_AREAS_ENERGY_SUSTAINABILITY                  28.946\n",
       "KEYNOTE_SPEAKER_INVITED                             219.453\n",
       "PARTNERSHIP_COUNTRY_N_A                              79.954\n",
       "PARTNERSHIP_NATIONAL                                 48.894\n",
       "PROJECT_AREAS_BIOMEDICAL_AND_HEALTHCARE_ENGINEE...   32.690\n",
       "PROJECT_AREAS_ENERGY_SECURITY                        35.708\n",
       "PROJECT_AREAS_NATURAL_PRODUCTS_BIOREFINERY_AND_...   44.638\n",
       "PROJECT_AREAS_SMART_LIVING_AND_SUSTAINABLE_CITIES    71.014\n",
       "PROJECT_AREAS_SMART_MANUFACTURING_AND_MATERIALS      62.194\n",
       "PROJECT_AREAS_SUSTAINABLE_AND_RESILIENT_URBANIS...   73.512\n",
       "SCHOLARSHIP_PHD                                      72.920\n",
       "SCHOLARSHIP_MASTER                                   19.180\n",
       "CONFERENCE_NATIONAL_INCLUDE_UNIVERSITY_LEVEL         44.664\n",
       "PAPER_INCENTIVE_NO_OF_PAPER_STAFF                   672.280\n",
       "SCORE_OVERALL_RANK                                  189.782"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# load cleaned data\n",
    "data = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "# bootstrap sample with z-score normalization\n",
    "\n",
    "\n",
    "def bootstrap_features(data, target_col='SCORE_AR', n_samples=1000):\n",
    "    # Separate features and target\n",
    "    features = data.drop(columns=[target_col])\n",
    "    target = data[target_col]\n",
    "    \n",
    "    # Bootstrap features\n",
    "    feature_indices = resample(\n",
    "        np.arange(len(features)), \n",
    "        n_samples=n_samples,\n",
    "        replace=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create bootstrapped dataset\n",
    "    bootstrapped_features = features.iloc[feature_indices]\n",
    "    bootstrapped_target = target.iloc[feature_indices]\n",
    "    \n",
    "    # Combine features and target\n",
    "    bootstrapped_data = pd.concat([bootstrapped_features, bootstrapped_target], axis=1)\n",
    "    \n",
    "    return bootstrapped_data\n",
    "\n",
    "# Apply bootstrapping\n",
    "bootstrapped_data = bootstrap_features(data, target_col='SCORE_AR', n_samples=1000)\n",
    "\n",
    "# Save bootstrapped data\n",
    "bootstrapped_data.to_csv('bootstrapped_data.csv', index=False)\n",
    "\n",
    "# calculate the mean of the top features\n",
    "top_feature_means = bootstrapped_data[top_features].mean()\n",
    "\n",
    "# display the top features and their mean values in dataframe\n",
    "top_feature_means_df = pd.DataFrame(top_feature_means, columns=['Mean'])\n",
    "top_feature_means_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.4108619517696752e-27\n"
     ]
    }
   ],
   "source": [
    "# Training a model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Continue with model training using bootstrapped data\n",
    "X = bootstrapped_data[top_features]\n",
    "y = bootstrapped_data['SCORE_AR']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate mean squared error\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46.31  47.767 44.954 47.767 47.767 43.443 44.954 44.954 44.954 47.767\n",
      " 46.31  44.954 47.767 43.443 46.31  43.443 46.31  47.767 39.4   46.31\n",
      " 43.443 47.767 46.31  39.4   39.4   44.954 44.954 43.443 46.31  46.31\n",
      " 44.954 46.31  46.31  39.4   44.954 47.767 44.954 47.767 39.4   43.443\n",
      " 46.31  39.4   46.31  43.443 43.443 39.4   43.443 47.767 43.443 46.31\n",
      " 46.31  46.31  46.31  47.767 44.954 39.4   46.31  43.443 46.31  43.443\n",
      " 43.443 46.31  47.767 43.443 43.443 46.31  43.443 43.443 46.31  46.31\n",
      " 39.4   47.767 47.767 43.443 47.767 43.443 39.4   46.31  46.31  46.31\n",
      " 47.767 39.4   47.767 47.767 39.4   39.4   39.4   39.4   46.31  44.954\n",
      " 44.954 39.4   44.954 44.954 39.4   44.954 47.767 43.443 43.443 39.4\n",
      " 46.31  39.4   46.31  43.443 39.4   47.767 44.954 46.31  44.954 44.954\n",
      " 39.4   44.954 47.767 44.954 39.4   47.767 43.443 44.954 39.4   43.443\n",
      " 43.443 46.31  47.767 44.954 39.4   46.31  47.767 46.31  47.767 47.767\n",
      " 44.954 47.767 46.31  47.767 44.954 44.954 46.31  43.443 43.443 47.767\n",
      " 39.4   47.767 46.31  46.31  46.31  46.31  46.31  44.954 43.443 46.31\n",
      " 39.4   39.4   39.4   39.4   44.954 39.4   46.31  47.767 39.4   44.954\n",
      " 44.954 39.4   47.767 39.4   44.954 43.443 46.31  44.954 39.4   46.31\n",
      " 39.4   39.4   43.443 46.31  46.31  43.443 44.954 39.4   47.767 39.4\n",
      " 39.4   44.954 39.4   43.443 43.443 46.31  47.767 39.4   39.4   44.954\n",
      " 43.443 47.767 46.31  43.443 46.31  44.954 44.954 39.4   47.767 46.31\n",
      " 43.443 44.954 39.4   39.4   46.31  44.954 47.767 44.954 46.31  46.31\n",
      " 44.954 46.31  44.954 43.443 44.954 44.954 46.31  46.31  39.4   39.4\n",
      " 43.443 39.4   44.954 46.31  39.4   39.4   43.443 43.443 44.954 46.31\n",
      " 43.443 39.4   46.31  46.31  39.4   43.443 39.4   46.31  47.767 47.767\n",
      " 44.954 39.4   39.4   44.954 44.954 44.954 46.31  39.4   46.31  44.954\n",
      " 39.4   46.31  46.31  44.954 39.4   44.954 39.4   47.767 43.443 43.443\n",
      " 43.443 44.954 47.767 39.4   46.31  39.4   46.31  39.4   47.767 46.31\n",
      " 44.954 39.4   39.4   46.31  44.954 44.954 47.767 44.954 44.954 44.954\n",
      " 43.443 47.767 39.4   46.31  39.4   47.767 46.31  47.767 44.954 46.31\n",
      " 44.954 39.4   39.4   46.31  46.31  47.767 47.767 44.954 46.31  39.4\n",
      " 47.767 47.767 39.4   47.767 44.954 46.31  39.4   46.31  47.767 47.767\n",
      " 39.4   44.954 43.443 39.4   43.443 43.443 44.954 43.443 43.443 44.954\n",
      " 43.443 43.443 43.443 39.4   39.4   39.4   44.954 47.767 43.443 43.443\n",
      " 44.954 43.443 39.4   47.767 46.31  43.443 39.4   46.31  47.767 46.31\n",
      " 39.4   46.31  44.954 46.31  43.443 43.443 44.954 39.4   43.443 47.767\n",
      " 43.443 43.443 39.4   46.31  43.443 44.954 46.31  47.767 39.4   47.767\n",
      " 46.31  46.31  46.31  47.767 46.31  47.767 46.31  44.954 46.31  47.767\n",
      " 43.443 46.31  43.443 44.954 39.4   44.954 46.31  43.443 43.443 47.767\n",
      " 43.443 47.767 39.4   46.31  47.767 39.4   43.443 43.443 39.4   43.443\n",
      " 39.4   47.767 47.767 39.4   47.767 47.767 47.767 44.954 46.31  43.443\n",
      " 44.954 47.767 39.4   47.767 46.31  47.767 39.4   46.31  47.767 46.31\n",
      " 43.443 43.443 47.767 46.31  39.4   47.767 43.443 43.443 47.767 46.31\n",
      " 43.443 46.31  43.443 43.443 44.954 43.443 39.4   47.767 47.767 46.31\n",
      " 43.443 39.4   46.31  44.954 46.31  46.31  43.443 44.954 46.31  39.4\n",
      " 39.4   47.767 44.954 44.954 47.767 46.31  44.954 39.4   39.4   43.443\n",
      " 44.954 46.31  47.767 47.767 46.31  43.443 47.767 44.954 43.443 44.954\n",
      " 39.4   43.443 47.767 43.443 43.443 43.443 43.443 44.954 39.4   46.31\n",
      " 43.443 47.767 43.443 47.767 44.954 47.767 46.31  39.4   47.767 47.767\n",
      " 39.4   46.31  43.443 47.767 39.4   44.954 39.4   44.954 46.31  43.443\n",
      " 39.4   47.767 46.31  39.4   47.767 39.4   44.954 39.4   39.4   39.4\n",
      " 46.31  39.4   47.767 44.954 44.954 39.4   46.31  46.31  47.767 39.4\n",
      " 44.954 46.31  39.4   46.31  46.31  44.954 43.443 47.767 47.767 44.954\n",
      " 46.31  39.4   46.31  44.954 47.767 46.31  47.767 39.4   47.767 47.767\n",
      " 43.443 43.443 43.443 47.767 44.954 47.767 44.954 44.954 43.443 46.31\n",
      " 39.4   43.443 43.443 46.31  39.4   47.767 47.767 43.443 39.4   43.443\n",
      " 44.954 43.443 43.443 47.767 47.767 47.767 44.954 47.767 39.4   46.31\n",
      " 39.4   39.4   47.767 46.31  46.31  46.31  44.954 47.767 46.31  44.954\n",
      " 43.443 43.443 44.954 44.954 47.767 47.767 43.443 46.31  43.443 46.31\n",
      " 46.31  47.767 39.4   39.4   44.954 47.767 46.31  39.4   46.31  39.4\n",
      " 39.4   39.4   47.767 43.443 46.31  47.767 47.767 47.767 47.767 47.767\n",
      " 44.954 46.31  47.767 46.31  44.954 44.954 46.31  39.4   43.443 39.4\n",
      " 39.4   39.4   47.767 44.954 39.4   44.954 46.31  43.443 46.31  46.31\n",
      " 47.767 43.443 46.31  46.31  43.443 43.443 46.31  43.443 46.31  46.31\n",
      " 47.767 39.4   46.31  44.954 39.4   39.4   39.4   47.767 46.31  47.767\n",
      " 46.31  47.767 47.767 44.954 47.767 43.443 44.954 47.767 39.4   43.443\n",
      " 43.443 43.443 44.954 47.767 47.767 39.4   39.4   43.443 39.4   44.954\n",
      " 47.767 43.443 39.4   44.954 44.954 39.4   47.767 39.4   43.443 39.4\n",
      " 44.954 39.4   47.767 46.31  39.4   47.767 47.767 44.954 47.767 47.767\n",
      " 47.767 47.767 43.443 43.443 44.954 39.4   47.767 39.4   39.4   44.954\n",
      " 47.767 47.767 46.31  39.4   39.4   43.443 46.31  43.443 43.443 43.443\n",
      " 44.954 44.954 43.443 46.31  39.4   46.31  47.767 44.954 39.4   39.4\n",
      " 47.767 47.767 43.443 44.954 44.954 46.31  43.443 43.443 43.443 43.443\n",
      " 44.954 44.954 43.443 46.31  39.4   39.4   46.31  43.443 44.954 39.4\n",
      " 47.767 47.767 46.31  43.443 39.4   43.443 39.4   46.31  46.31  47.767\n",
      " 43.443 47.767 43.443 47.767 44.954 44.954 44.954 44.954 39.4   44.954\n",
      " 46.31  46.31  39.4   44.954 44.954 44.954 47.767 43.443 47.767 43.443\n",
      " 44.954 44.954 47.767 47.767 43.443 46.31  43.443 47.767 47.767 39.4\n",
      " 47.767 39.4   46.31  43.443 43.443 39.4   43.443 47.767 44.954 39.4\n",
      " 43.443 39.4   39.4   44.954 47.767 39.4   43.443 46.31  39.4   39.4\n",
      " 44.954 47.767 46.31  43.443 46.31  43.443 47.767 43.443 44.954 44.954\n",
      " 44.954 44.954 46.31  47.767 43.443 43.443 44.954 44.954 39.4   47.767\n",
      " 46.31  43.443 39.4   39.4   43.443 46.31  39.4   39.4   47.767 46.31\n",
      " 39.4   46.31  43.443 44.954 39.4   47.767 43.443 46.31  43.443 39.4\n",
      " 46.31  44.954 43.443 39.4   47.767 46.31  43.443 43.443 44.954 44.954\n",
      " 47.767 47.767 39.4   39.4   47.767 47.767 46.31  44.954 39.4   44.954\n",
      " 44.954 47.767 46.31  43.443 46.31  46.31  44.954 46.31  39.4   44.954\n",
      " 39.4   43.443 44.954 43.443 44.954 47.767 46.31  47.767 43.443 46.31\n",
      " 44.954 46.31  39.4   46.31  39.4   46.31  39.4   43.443 47.767 44.954\n",
      " 46.31  47.767 44.954 44.954 39.4   43.443 43.443 47.767 43.443 46.31\n",
      " 43.443 47.767 43.443 46.31  39.4   47.767 39.4   39.4   39.4   44.954\n",
      " 44.954 39.4   47.767 46.31  46.31  43.443 47.767 44.954 39.4   43.443\n",
      " 46.31  44.954 44.954 39.4   46.31  47.767 44.954 39.4   47.767 46.31\n",
      " 44.954 47.767 47.767 47.767 44.954 44.954 43.443 46.31  39.4   47.767\n",
      " 43.443 39.4   43.443 44.954 47.767 39.4   39.4   39.4   39.4   39.4\n",
      " 43.443 47.767 44.954 44.954 44.954 44.954 43.443 46.31  47.767 39.4\n",
      " 46.31  44.954 46.31  47.767 39.4   39.4   47.767 47.767 44.954 39.4\n",
      " 46.31  43.443 43.443 47.767 44.954 43.443 39.4   47.767 46.31  47.767\n",
      " 46.31  47.767 47.767 47.767 46.31  46.31  47.767 43.443 44.954 44.954\n",
      " 44.954 46.31  46.31  43.443 44.954 44.954 47.767 46.31  44.954 43.443\n",
      " 43.443 44.954 46.31  43.443 47.767 43.443 39.4   39.4   46.31  44.954]\n"
     ]
    }
   ],
   "source": [
    "# Increase each feature in the dataset by 20%\n",
    "X_increased = X * 1.2\n",
    "\n",
    "# Predict the SCORE_AR for the modified dataset\n",
    "y_pred_increased = model.predict(X_increased)\n",
    "\n",
    "# Display the predictions\n",
    "print(y_pred_increased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sharu\\AppData\\Local\\Temp\\ipykernel_20024\\3146108622.py:36: OptimizeWarning: Unknown solver options: gtol\n",
      "  result = minimize(\n",
      "C:\\Users\\sharu\\AppData\\Local\\Temp\\ipykernel_20024\\3146108622.py:36: OptimizeWarning: Unknown solver options: gtol\n",
      "  result = minimize(\n",
      "C:\\Users\\sharu\\AppData\\Local\\Temp\\ipykernel_20024\\3146108622.py:36: OptimizeWarning: Unknown solver options: gtol\n",
      "  result = minimize(\n",
      "C:\\Users\\sharu\\AppData\\Local\\Temp\\ipykernel_20024\\3146108622.py:36: OptimizeWarning: Unknown solver options: gtol\n",
      "  result = minimize(\n",
      "C:\\Users\\sharu\\AppData\\Local\\Temp\\ipykernel_20024\\3146108622.py:36: OptimizeWarning: Unknown solver options: gtol\n",
      "  result = minimize(\n",
      "C:\\Users\\sharu\\AppData\\Local\\Temp\\ipykernel_20024\\3146108622.py:36: OptimizeWarning: Unknown solver options: gtol\n",
      "  result = minimize(\n",
      "C:\\Users\\sharu\\AppData\\Local\\Temp\\ipykernel_20024\\3146108622.py:36: OptimizeWarning: Unknown solver options: ftol, gtol\n",
      "  result = minimize(\n",
      "C:\\Users\\sharu\\AppData\\Local\\Temp\\ipykernel_20024\\3146108622.py:36: OptimizeWarning: Unknown solver options: ftol, gtol\n",
      "  result = minimize(\n",
      "C:\\Users\\sharu\\AppData\\Local\\Temp\\ipykernel_20024\\3146108622.py:36: OptimizeWarning: Unknown solver options: ftol, gtol\n",
      "  result = minimize(\n",
      "C:\\Users\\sharu\\AppData\\Local\\Temp\\ipykernel_20024\\3146108622.py:36: OptimizeWarning: Unknown solver options: ftol, gtol\n",
      "  result = minimize(\n",
      "C:\\Users\\sharu\\AppData\\Local\\Temp\\ipykernel_20024\\3146108622.py:36: OptimizeWarning: Unknown solver options: ftol, gtol\n",
      "  result = minimize(\n",
      "C:\\Users\\sharu\\AppData\\Local\\Temp\\ipykernel_20024\\3146108622.py:36: OptimizeWarning: Unknown solver options: ftol, gtol\n",
      "  result = minimize(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best optimization method achieved error: 3.0810\n",
      "Optimization status: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "Desired Score: 50\n",
      "Achieved Score: 46.92\n",
      "Optimization Success: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Feature</th>\n",
       "      <th>PROJECT_AREAS_ENERGY_SUSTAINABILITY</th>\n",
       "      <th>KEYNOTE_SPEAKER_INVITED</th>\n",
       "      <th>PARTNERSHIP_COUNTRY_N_A</th>\n",
       "      <th>PARTNERSHIP_NATIONAL</th>\n",
       "      <th>PROJECT_AREAS_BIOMEDICAL_AND_HEALTHCARE_ENGINEERING</th>\n",
       "      <th>PROJECT_AREAS_ENERGY_SECURITY</th>\n",
       "      <th>PROJECT_AREAS_NATURAL_PRODUCTS_BIOREFINERY_AND_BIOTECHNOLOGY</th>\n",
       "      <th>PROJECT_AREAS_SMART_LIVING_AND_SUSTAINABLE_CITIES</th>\n",
       "      <th>PROJECT_AREAS_SMART_MANUFACTURING_AND_MATERIALS</th>\n",
       "      <th>PROJECT_AREAS_SUSTAINABLE_AND_RESILIENT_URBANISATION</th>\n",
       "      <th>SCHOLARSHIP_PHD</th>\n",
       "      <th>SCHOLARSHIP_MASTER</th>\n",
       "      <th>CONFERENCE_NATIONAL_INCLUDE_UNIVERSITY_LEVEL</th>\n",
       "      <th>PAPER_INCENTIVE_NO_OF_PAPER_STAFF</th>\n",
       "      <th>SCORE_OVERALL_RANK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.419</td>\n",
       "      <td>329.1795</td>\n",
       "      <td>119.931</td>\n",
       "      <td>73.341</td>\n",
       "      <td>49.035</td>\n",
       "      <td>53.562</td>\n",
       "      <td>66.957</td>\n",
       "      <td>106.521</td>\n",
       "      <td>93.291</td>\n",
       "      <td>110.268</td>\n",
       "      <td>109.38</td>\n",
       "      <td>28.77</td>\n",
       "      <td>66.996</td>\n",
       "      <td>1008.42</td>\n",
       "      <td>284.673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Feature  PROJECT_AREAS_ENERGY_SUSTAINABILITY  KEYNOTE_SPEAKER_INVITED  \\\n",
       "0                                     43.419                 329.1795   \n",
       "\n",
       "Feature  PARTNERSHIP_COUNTRY_N_A  PARTNERSHIP_NATIONAL  \\\n",
       "0                        119.931                73.341   \n",
       "\n",
       "Feature  PROJECT_AREAS_BIOMEDICAL_AND_HEALTHCARE_ENGINEERING  \\\n",
       "0                                                   49.035     \n",
       "\n",
       "Feature  PROJECT_AREAS_ENERGY_SECURITY  \\\n",
       "0                               53.562   \n",
       "\n",
       "Feature  PROJECT_AREAS_NATURAL_PRODUCTS_BIOREFINERY_AND_BIOTECHNOLOGY  \\\n",
       "0                                                   66.957              \n",
       "\n",
       "Feature  PROJECT_AREAS_SMART_LIVING_AND_SUSTAINABLE_CITIES  \\\n",
       "0                                                  106.521   \n",
       "\n",
       "Feature  PROJECT_AREAS_SMART_MANUFACTURING_AND_MATERIALS  \\\n",
       "0                                                 93.291   \n",
       "\n",
       "Feature  PROJECT_AREAS_SUSTAINABLE_AND_RESILIENT_URBANISATION  \\\n",
       "0                                                  110.268      \n",
       "\n",
       "Feature  SCHOLARSHIP_PHD  SCHOLARSHIP_MASTER  \\\n",
       "0                 109.38               28.77   \n",
       "\n",
       "Feature  CONFERENCE_NATIONAL_INCLUDE_UNIVERSITY_LEVEL  \\\n",
       "0                                              66.996   \n",
       "\n",
       "Feature  PAPER_INCENTIVE_NO_OF_PAPER_STAFF  SCORE_OVERALL_RANK  \n",
       "0                                  1008.42             284.673  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def predict_inverse(model, desired_score, top_features, feature_bounds=None, max_iter=2000):\n",
    "    \"\"\"\n",
    "    Predict feature values for desired score using optimization\n",
    "    \"\"\"\n",
    "    initial_guess = bootstrapped_data[top_features].mean().values\n",
    "    \n",
    "    if feature_bounds is None:\n",
    "        feature_bounds = []\n",
    "        for feature in top_features:\n",
    "            min_val = bootstrapped_data[feature].min()\n",
    "            max_val = bootstrapped_data[feature].max() * 100\n",
    "            feature_bounds.append((min_val, max_val))\n",
    "    \n",
    "    def objective(x):\n",
    "        x_df = pd.DataFrame([x], columns=top_features)\n",
    "        pred = model.predict(x_df)[0]\n",
    "        return abs(pred - desired_score)  # Changed to absolute difference\n",
    "    \n",
    "    best_result = None\n",
    "    best_score = float('inf')\n",
    "    \n",
    "    # Try multiple optimization methods\n",
    "    methods = ['L-BFGS-B', 'SLSQP', 'Nelder-Mead']\n",
    "    \n",
    "    # Try more starting points\n",
    "    multipliers = [0.5, 1.0, 1.5, 2.0, 5.0, 10.0]\n",
    "    starting_points = [initial_guess * m for m in multipliers]\n",
    "    \n",
    "    for method in methods:\n",
    "        for start in starting_points:\n",
    "            try:\n",
    "                result = minimize(\n",
    "                    objective,\n",
    "                    start,\n",
    "                    bounds=feature_bounds if method != 'Nelder-Mead' else None,\n",
    "                    method=method,\n",
    "                    options={\n",
    "                        'maxiter': max_iter,\n",
    "                        'ftol': 1e-8,\n",
    "                        'gtol': 1e-8\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                if result.fun < best_score:\n",
    "                    best_score = result.fun\n",
    "                    best_result = result\n",
    "                    \n",
    "                # Early stop if we're close enough\n",
    "                if best_score < 0.1:\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Method {method} failed: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    optimized_values = pd.DataFrame([best_result.x], columns=top_features)\n",
    "    predicted = model.predict(optimized_values)[0]\n",
    "    \n",
    "    print(f\"Best optimization method achieved error: {best_score:.4f}\")\n",
    "    print(f\"Optimization status: {best_result.message}\")\n",
    "    \n",
    "    return optimized_values, predicted\n",
    "\n",
    "# Example usage\n",
    "desired_score = 50\n",
    "feature_values, predicted_score = predict_inverse(model, desired_score, top_features)\n",
    "\n",
    "print(f\"Desired Score: {desired_score}\")\n",
    "print(f\"Achieved Score: {predicted_score:.2f}\")\n",
    "print(f\"Optimization Success: {abs(desired_score - predicted_score) < 1}\")\n",
    "display(feature_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandasai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
